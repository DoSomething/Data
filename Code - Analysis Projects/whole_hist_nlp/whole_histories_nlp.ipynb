{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"whole_histories_nlp.ipynb","provenance":[],"authorship_tag":"ABX9TyPbivBVuHdSquYvFCI2EfKD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Gq_2cMEm1jXz","executionInfo":{"status":"ok","timestamp":1621473748657,"user_tz":240,"elapsed":328,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","import plotnine as pn\n","from plotnine import ggplot, geom_point, aes, geom_col, geom_line, geom_boxplot, geom_bar\n","from scipy.stats import ttest_ind\n","pd.set_option('max_rows', 200)\n","pd.set_option('max_colwidth', 150)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3MV4w0f1nV3","executionInfo":{"status":"ok","timestamp":1621471721468,"user_tz":240,"elapsed":355,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}},"outputId":"044a2acc-2c71-4690-8416-a072d3f824b2"},"source":["import psycopg2\n","import pandas.io.sql as sqlio"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n","  \"\"\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NS3boyxj1ucu","executionInfo":{"status":"ok","timestamp":1621471724189,"user_tz":240,"elapsed":360,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["conn = psycopg2.connect(dbname='quasar_prod_warehouse', user='kkennovin', password='eBC$O55$Lcko', host='quasar-prod.c9ajz690mens.us-east-1.rds.amazonaws.com', port='5432')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dyg3QwrT10BZ","executionInfo":{"status":"ok","timestamp":1621471743121,"user_tz":240,"elapsed":233,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["\n","sql_q1 = \"\"\"select \n","\tnorthstar_id\n",",\ttext \n","from \n","\tposts \n","where \n","\tcampaign_id = '9115' and \n","\taction_id = 1126\n","    \"\"\"\n","\n","sql_q2 = \"\"\"select \n","\tnorthstar_id\n",",\ttext \n","from \n","\tposts \n","where \n","\tcampaign_id = '9115' and \n","\taction_id = 1127\n","    \"\"\"\n","\n","sql_q3 = \"\"\"select \n","\tnorthstar_id\n",",\ttext \n","from \n","\tposts \n","where \n","\tcampaign_id = '9115' and \n","\taction_id = 1128\n","    \"\"\""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDRpbWj7P2oQ","executionInfo":{"status":"ok","timestamp":1621471804278,"user_tz":240,"elapsed":1160,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["data_q1 = sqlio.read_sql_query(sql_q1, conn)\n","data_q2 = sqlio.read_sql_query(sql_q2, conn)\n","data_q3 = sqlio.read_sql_query(sql_q3, conn)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5MXvsLTQDa_","executionInfo":{"status":"ok","timestamp":1621471827629,"user_tz":240,"elapsed":231,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["conn = None"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"vUVfL3qNQ0y-","executionInfo":{"status":"ok","timestamp":1621472105526,"user_tz":240,"elapsed":212,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["# Apply a first round of text cleaning techniques\n","import re\n","import string\n","\n","def clean_text_round1(text):\n","    '''Make text lowercase, remove punctuation'''\n","    text = text.lower()\n","    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n","    return text\n","\n","round1 = lambda x: clean_text_round1(x)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"iflf7enwRNM4"},"source":["# Let's take a look at the updated text\n","data_clean_q1 = pd.DataFrame(data_q1.text.apply(round1))\n","#data_clean_q1.sample(50)\n","data_clean_q2 = pd.DataFrame(data_q2.text.apply(round1))\n","#data_clean_q2.sample(50)\n","data_clean_q3 = pd.DataFrame(data_q3.text.apply(round1))\n","#data_clean_q3.sample(50)\n","\n","# looks good! I don't see any other obvious cleaning needs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXCCH9KyR81u","executionInfo":{"status":"ok","timestamp":1621475234602,"user_tz":240,"elapsed":9156,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["# We are going to create a document-term matrix using CountVectorizer, and exclude common English stop words for each question\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","cv_q1 = CountVectorizer(stop_words='english')\n","data_cv_q1 = cv_q1.fit_transform(data_clean_q1.text)\n","dtm_q1 = pd.DataFrame(data_cv_q1.toarray(), columns=cv_q1.get_feature_names())\n","dtm_q1.index = data_clean_q1.index\n","\n","cv_q2 = CountVectorizer(stop_words='english')\n","data_cv_q2 = cv_q2.fit_transform(data_clean_q2.text)\n","dtm_q2 = pd.DataFrame(data_cv_q2.toarray(), columns=cv_q2.get_feature_names())\n","dtm_q2.index = data_clean_q2.index\n","\n","cv_q3 = CountVectorizer(stop_words='english')\n","data_cv_q3 = cv_q3.fit_transform(data_clean_q3.text)\n","dtm_q3 = pd.DataFrame(data_cv_q3.toarray(), columns=cv_q3.get_feature_names())\n","dtm_q3.index = data_clean_q3.index\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlLPkdd7Y-LY"},"source":[""],"execution_count":null,"outputs":[]}]}