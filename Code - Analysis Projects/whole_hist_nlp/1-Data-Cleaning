{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1-Data-Cleaning","provenance":[],"machine_shape":"hm","mount_file_id":"1rg0_wc9h8lHem-TwuYLaGWMT3VD9YHpW","authorship_tag":"ABX9TyMw+FROD7Vp4XphMaFP9Hka"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YPtJRavW_4vI"},"source":["# packages & set options"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZZ_i4drn_yy7","executionInfo":{"status":"ok","timestamp":1622474410891,"user_tz":240,"elapsed":2554,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}},"outputId":"62869013-95af-410e-9d64-10c1dc1f4721"},"source":["import numpy as np\n","import pandas as pd \n","\n","import re\n","import string\n","\n","import psycopg2\n","import pandas.io.sql as sqlio\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","from nltk import word_tokenize, pos_tag\n","\n","import gensim\n","from gensim import matutils, models\n","import scipy.sparse\n","\n","from tqdm import tqdm_notebook as tqdm\n","from pprint import pprint\n","\n","import os\n","import pickle\n","\n","pd.set_option('max_rows', 200)\n","pd.set_option('max_colwidth', 150)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n","  \"\"\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"D8RaFO23ATRI"},"source":["# db connection, read data for each Whole Histories question"]},{"cell_type":"code","metadata":{"id":"xMdUfp_7AHd-","executionInfo":{"status":"ok","timestamp":1622474415347,"user_tz":240,"elapsed":1990,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["conn = psycopg2.connect(dbname='quasar_prod_warehouse', user='kkennovin', password='eBC$O55$Lcko', host='quasar-prod.c9ajz690mens.us-east-1.rds.amazonaws.com', port='5432')\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tu2zRPbcAYNu","executionInfo":{"status":"ok","timestamp":1622474417630,"user_tz":240,"elapsed":442,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["sql_q1 = \"\"\"select \n","\tnorthstar_id\n",",\ttext \n","from \n","\tposts \n","where \n","\tcampaign_id = '9115' and \n","\taction_id = 1126\n","    \"\"\"\n","\n","sql_q2 = \"\"\"select \n","\tnorthstar_id\n",",\ttext \n","from \n","\tposts \n","where \n","\tcampaign_id = '9115' and \n","\taction_id = 1127\n","    \"\"\"\n","\n","sql_q3 = \"\"\"select \n","\tnorthstar_id\n",",\ttext \n","from \n","\tposts \n","where \n","\tcampaign_id = '9115' and \n","\taction_id = 1128\n","    \"\"\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"_U84uglwAc51","executionInfo":{"status":"ok","timestamp":1622474423659,"user_tz":240,"elapsed":3757,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["data_q1 = sqlio.read_sql_query(sql_q1, conn)\n","data_q2 = sqlio.read_sql_query(sql_q2, conn)\n","data_q3 = sqlio.read_sql_query(sql_q3, conn)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSUQ82WqAfIA","executionInfo":{"status":"ok","timestamp":1622474425122,"user_tz":240,"elapsed":252,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["conn = None"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-q1dWuqmAjGM"},"source":["# data cleaning: make lowercase & remove punctuation"]},{"cell_type":"code","metadata":{"id":"eMN-3e2MAiV_","executionInfo":{"status":"ok","timestamp":1622474452162,"user_tz":240,"elapsed":336,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["# Apply a first round of text cleaning techniques, make text lowercase and remove punctuation\n","def clean_text_round1(text):\n","    text = text.lower()\n","    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n","    return text\n","\n","round1 = lambda x: clean_text_round1(x)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"vdrYj5fcAqcU","executionInfo":{"status":"ok","timestamp":1622474454538,"user_tz":240,"elapsed":565,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["# Let's take a look at the updated text\n","data_clean_q1 = pd.DataFrame(data_q1.text.apply(round1))\n","#data_clean_q1.sample(50)\n","data_clean_q2 = pd.DataFrame(data_q2.text.apply(round1))\n","#data_clean_q2.sample(50)\n","data_clean_q3 = pd.DataFrame(data_q3.text.apply(round1))\n","#data_clean_q3.sample(50)\n","\n","# looks good! I don't see any other obvious cleaning needs"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kaKNQJL8A1Bv"},"source":["# count vectorizer & document term matrix"]},{"cell_type":"code","metadata":{"id":"AWXJl4d1AtLo","executionInfo":{"status":"ok","timestamp":1622474476746,"user_tz":240,"elapsed":9077,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["# We are going to create a document-term matrix using CountVectorizer, and exclude common English stop words for each question\n","\n","cv_q1 = CountVectorizer(stop_words='english')\n","data_cv_q1 = cv_q1.fit_transform(data_clean_q1.text)\n","dtm_q1 = pd.DataFrame(data_cv_q1.toarray(), columns=cv_q1.get_feature_names())\n","dtm_q1.index = data_clean_q1.index\n","\n","cv_q2 = CountVectorizer(stop_words='english')\n","data_cv_q2 = cv_q2.fit_transform(data_clean_q2.text)\n","dtm_q2 = pd.DataFrame(data_cv_q2.toarray(), columns=cv_q2.get_feature_names())\n","dtm_q2.index = data_clean_q2.index\n","\n","cv_q3 = CountVectorizer(stop_words='english')\n","data_cv_q3 = cv_q3.fit_transform(data_clean_q3.text)\n","dtm_q3 = pd.DataFrame(data_cv_q3.toarray(), columns=cv_q3.get_feature_names())\n","dtm_q3.index = data_clean_q3.index"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9v-QdO19BgcG"},"source":["# save data with pickle"]},{"cell_type":"code","metadata":{"id":"-_EsHjCTDZWz"},"source":["# reset pwd (with mounted google drive)\n","os.chdir('/content/drive/Shareddrives/Team Data & Insights/1. Analytics - Projects & Analysis/*IN PROGRESS* 2021 Q2 Whole Histories NLP')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0rneS3qEJP5"},"source":["%pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H0G1uWdpBKbV","executionInfo":{"status":"ok","timestamp":1622474584885,"user_tz":240,"elapsed":85316,"user":{"displayName":"Kat Kennovin","photoUrl":"","userId":"13651926827835921572"}}},"source":["# Let's pickle it for later use\n","dtm_q1.to_pickle('dtm_q1.pkl')\n","dtm_q2.to_pickle('dtm_q2.pkl')\n","dtm_q3.to_pickle('dtm_q3.pkl')\n","\n","# Let's also pickle the cleaned data (before we put it in document-term matrix format) and the CountVectorizer object\n","data_clean_q1.to_pickle('data_clean_q1.pkl')\n","pickle.dump(cv_q1, open('cv_q1.pkl', 'wb'))\n","\n","data_clean_q2.to_pickle('data_clean_q2.pkl')\n","pickle.dump(cv_q2, open('cv_q2.pkl', 'wb'))\n","\n","data_clean_q3.to_pickle('data_clean_q3.pkl')\n","pickle.dump(cv_q3, open('cv_q3.pkl', 'wb'))\n"],"execution_count":10,"outputs":[]}]}