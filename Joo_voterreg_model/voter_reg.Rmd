---
title: "voter_reg_modeling"
output: html_document
---

# 1. Sources & Libraries 

```{r, quietly=TRUE}
source('config/init.R')
source('config/pgConnect.R')
source('config/voter_regfunctions.R') # all functions are here
pg <- pgConnect()

packages.used <- c("lubridate", "ggplot2", "caret", 
                   "reshape2", "dplyr", 
                   "MLmetrics", "e1071", "tree", "rstanarm", "parallel", 
                   "doMC", "xgboost")

#check packages that need to be installed
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))

#install additional packages 
if (length(packages.needed) > 0) {
  install.packages(packages.needed, dependencies = TRUE)
}

library(lubridate)
library(reshape2)
library(caret)
library(ggplot2)
library(MLmetrics)
library(tree)
library(nnet)
library(parallel)
library(doMC)
library(mice)
library(xgboost)
library(rpart)
library(tree.bins)
library(gbm)
library(randomForest)
library(ggthemes)
library(dplyr)
```

# 2. Load datasets 

```{r}
# Users dataset 

users_query <- 
"SELECT u.northstar_id,
u.created_at,
u.last_logged_in,
u.last_accessed,
u.SOURCE,
u.birthdate,
u.first_name,
u.state,
u.zipcode,
u.cio_status,
u.sms_status,
u.voter_registration_status
FROM users u
WHERE u.subscribed_member = 'true'
	AND u.country = 'US'
	AND u.birthdate <= current_date - INTERVAL '18 years'" # removing underage members in users file 

users <- runQuery(users_query)

# phoenix_events dataset 

phoenix_query <- "SELECT 
	northstar_id,
	event_datetime,
	event_name,
	event_source,
	campaign_id,
	page_utm_medium,
	parent_source,
	browser_size
FROM phoenix_events
WHERE northstar_id IS NOT NULL 
	AND event_name IN ('view', 'visit', 'open modal', 'share action completed', 'clicked voter registration action', 'facebook share posted', 'photo-submission_action', 'clicked register-submit', 'Successful Reportback', 'text-submission-action', 'referral-submission-action')"

phoenix <- runQuery(phoenix_query)

# member_event_log dataset 

mel_query <- "SELECT 
	m.northstar_id,
	m.timestamp,
	m.action_type,
	m.SOURCE
FROM member_event_log m
WHERE m.northstar_id IS NOT NULL"

mel <- runQuery(mel_query)

# campaign_activity dataset 

ca_query <- "SELECT c.northstar_id,
c.campaign_run_id,
c.post_type,
c.reportback_volume,
c.post_status,
c.quantity,
c.signup_source,
c.post_source,
c.signup_created_at,
c.reported_back,
c.post_attribution_date
FROM campaign_activity c
WHERE c.northstar_id IS NOT NULL"

campaign <- runQuery(ca_query)

# campaign_info

ca_info_query <- "SELECT 
campaign_run_id,
campaign_type,
campaign_verb,
campaign_cause_type
FROM campaign_info
WHERE campaign_run_id IS NOT NULL"

campaign_info <- runQuery(ca_info_query)

# email data

email_query <- "SELECT customer_id AS northstar_id,
email_address,
template_id, 
timestamp,
event_type
FROM email_event 
WHERE customer_id IS NOT NULL"

email <- runQuery(email_query)

# SMS

SMS_mes <- "SELECT 
northstar_id,
click_time AS SMS_time,
'SMS message' AS action_type
FROM bertly_clicks
WHERE northstar_id IS NOT NULL
UNION ALL 
	SELECT 
		id AS northstar_id,
		last_messaged_at AS SMS_time,
		'SMS link click' AS action_type
	FROM northstar.users 
	WHERE id IS NOT NULL 
		AND last_messaged_at IS NOT NULL"

sms <- runQuery(SMS_mes)

# Turbovote file 
turbo_query <- "SELECT 
	nsid AS northstar_id,
	SOURCE,
	campaign_id,
	ds_vr_status,
	ds_registration_date,
	file
FROM turbovote_file
WHERE nsid IS NOT null"

turbo <- runQuery(turbo_query)  
```

# Save as R data files 

```{r}
saveRDS(users, "Rdata/users.rds")
saveRDS(phoenix, "Rdata/phoenix.rds")
saveRDS(campaign, "Rdata/campaign.rds")
saveRDS(email, "Rdata/email.rds")
saveRDS(sms, "Rdata/sms.rds")
saveRDS(turbo, "Rdata/turbo.rds")
saveRDS(mel, "Rdata/mel.rds")
saveRDS(campaign_info, "Rdata/campaign_info.rds")
```

# Load R data files 

```{r}
users <- readRDS("Rdata/users.rds")
phoenix <- readRDS("Rdata/phoenix.rds")
campaign <- readRDS("Rdata/campaign.rds")
email <- readRDS("Rdata/email.rds")
sms <- readRDS("Rdata/sms.rds")
turbo <- readRDS("Rdata/turbo.rds")
mel <- readRDS("Rdata/mel.rds")
campaign_info <- readRDS("Rdata/campaign_info.rds")
```


# Data wrangling 

## Remove records of under 18 northstar_ids in all datasets 

```{r}
# only keep rows whose age < 18, in US, and members in relevant datasets. 
phoenix <- remove18(phoenix, users)
campaign <- remove18(campaign, users)
email <- remove18(email, users)
sms <- remove18(sms, users)
turbo <- remove18(turbo, users)
mel <- remove18(mel, users)
```

## Extracting predicted feature (voter registration status)

```{r}
# a part of this code will soon become obsolete as Jen is leading the sprint to combine for all columns 
reg_status <- predicted_feature(users, turbo, campaign, phoenix, email)
```


## Extracting demographic features 

```{r}
# gender feature 
gender <- gender_feature(users)

# age feature 
age <- age_feature(users)

# SES feature 
ses <- ses_feature(users)

# state and whether it turned blue/red in 2016 election 
state_politics <- dem_rep_feature(users)
```

## Extracting behavioral features 

```{r}
# returns variables of email clicked, converted, opened, unsubscribed & total number of email actions per northstar_id  
email_count <- email_feature(email)

# returns columns of SMS action by type & total number of sms actions per northstar_id 
sms_count <- sms_total_feature(sms)

# returns columns of browser size by northstar_id 
browser_size <- browser_size_feature(phoenix)

# returns number of total actions per northstar_id 
total_action <- total_actions_feature(phoenix, campaign, email, sms)

# whether or not someone has reportedback ever (according to campaigns)
rb_status <- rb_feature(campaign, users)

# returns time of day activity level (day broken down by "morning", "afternoon", "evening", "night")
time_of_day <- timeday_feature(mel, users) # potentially recategorize using tree.bins or rpart or recat? 

# monthly active membership eligible action count by action type 
mam_actions <- MAM_action_feature(mel)

# cause space 
cause_space <- cause_space_feature(users, campaign, campaign_info)

# months before last active
last_action <- last_action_feature(mel)
```

# Create a dataset with desired features 

```{r}
master <- 
  reg_status %>% 
  left_join(gender, by = "northstar_id") %>% 
  left_join(age, by = "northstar_id") %>%
  left_join(ses, by = "northstar_id") %>% 
  left_join(state_politics, by = "northstar_id") %>%
  left_join(email_count, by = "northstar_id") %>% 
  left_join(sms_count, by = "northstar_id") %>%
  left_join(browser_size, by = "northstar_id") %>% 
  left_join(total_action, by = "northstar_id") %>%
  left_join(rb_status, by = "northstar_id") %>%
  left_join(time_of_day, by = "northstar_id") %>%
  left_join(mam_actions, by = "northstar_id") %>%
  left_join(cause_space, by = "northstar_id") %>% 
  left_join(last_action, by = "northstar_id")
  
master <- replace_na_numeric(master) # replace NAs in numeric columns with 0's
# master <- multi_imput(master) # use multiple imputation to fill in for missing values (mice package)
master <- replace_na_else(master) # replace NAs in non-numeric columns with "unknown" 
```

## Identify & eliminate near zero-variance variables

(zero-variance variables are variables that have only a handful of unique values that occur with very low frequency - may need to be eliminated prior to modeling for fit to be stable)

```{r}
df_list <- remove_nzv(master) 

master <- df_list[[2]] # keeps only the dataframe
```

## Identify & eliminate highly correlated predictors

```{r}
df_list2 <- remove_highcor(master)

master <- df_list2[[3]] # keeps only the dataframe
```

# Find & remove linear dependencies 

```{r}
numeric_only <- master %>% select_if(is.numeric)
comboinfo <- findLinearCombos(numeric_only) # nothing to remove
```

## Descriptive Statistics 

```{r}
# distribution of voter_reg statuses 
voter_reg_freq <- 
  master %>% 
  group_by(voter_reg_status) %>% 
  tally

ggplot(voter_reg_freq, aes(x = reorder(voter_reg_status, n), y = n, fill = voter_reg_status)) + 
  geom_bar(stat = "identity") + 
  geom_text(aes(label = n), vjust = -0.5, size = 3) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Breakdown of DoSomething voter registration status",
       x = "voter registration status", 
       y = "frequency")
```

```{r}
voter_reg_gender <- 
  master %>% 
  group_by(voter_reg_status, gender) %>% 
  tally

# pie chart for gender breakdown 

# ses breakdown, behavioral stats (total action, reportback status), the NA's of categorical variables, what else?!? 
```

## Finalize master dataset with desired ordered factor levels 
(Creates a sample of no_interaction category data from NA's)

```{r}
master <- master_final(master)
```

## Remove datasets no longer needed to free up RAM 

```{r}
rm(age, browser_size, email_count, gender, rb_status, reg_status,
   ses, sms_count, state_politics, time_of_day, total_action, df_list, df_list2)

rm(campaign, email, mel, phoenix,
   sms, turbo, users)

rm(mam_actions, campaign_info, campaign_with_id, cause_space, comboinfo, output)

rm(numeric_only, voter_reg_freq, voter_reg_gender)
```


# Split into training & testing

### Divide into training and testing 

```{r}
in_train <- createDataPartition(y = master$voter_reg_status, p = 3 / 4, list = FALSE)
training <- master[in_train, ]
testing  <- master[-in_train, ]
```

The dataset is unbalanced because there is a significantly greater number of "interaction" than "registration complete" & "uncertain" values, which would bias the model into favoring predictions for those who have "interacted" with any voter registration CTA. I will use the caret upsample function to increase the other two values, with replacement. 

(The up sampling should be done to the training set ONLY. The testing set should maintain the unbalanced classes.)  

```{r}
up_train <- upSample(x = select(training, -c(voter_reg_status, northstar_id)),
                     y = training$voter_reg_status,
                     yname = "voter_reg_status") #upSample reduces the number of any_interaction values -- explore further (USE SMOTE??)
```

Centering and scaling data ensures that some features do not dominate the algorithm AND and the features are unit-independent. 

```{r}
preprocvalues <- preProcess(up_train, method = c("center", "scale")) # estimates required parameters to be centered & scaled 
train_transformed <- predict(preprocvalues, up_train) # this function actually centers and scales based on the parameters defined above 
test_transformed <- predict(preprocvalues, testing)
```

randomly sample b/c of memory issues....

```{r}
by_grp <- train_transformed %>% group_by(voter_reg_status)
train_transformed_sample <- sample_n(by_grp, 10000)
train_transformed_sample$state <- NULL

rm(master, by_grp, in_train, testing, train_transformed, training, up_train)
```


Using the caret package to set a 10-fold cross-validation for models with tuning parameters. 

```{r}
ctrl <- trainControl(method = "cv",
                     number = 10,
                     summaryFunction = multiClassSummary, # computes accuracy & Kappa statistics, sensitivity values - might substitute prSummary (precision & recall)...  explore
                     classProbs = TRUE)
```

## Tree 

```{r}
set.seed(12345)
options(mc.cores = parallel::detectCores())

tree_model <- tree(voter_reg_status ~ .,
                   data = train_transformed_sample) 
tree_predictions <- predict(tree_model, newdata = test_transformed, type = "class")
table_tree <- confusionMatrix(tree_predictions, test_transformed$voter_reg_status) # tree not predicting any "registration_complete" classes... ditch 

# simple accuracy rate
Accuracy(y_pred = tree_predictions, y_true = test_transformed$voter_reg_status) 

# AUC computations (true positive rate vs. false positive rate)
# AUC for registration_complete 
AUC_function(tree_predictions, test_transformed, "registration_complete")

# AUC for uncertain 
AUC_function(tree_predictions, test_transformed, "registration_started")

# AUC for interaction 
AUC_function(tree_predictions, test_transformed, "any_interaction") # error - integer overflow ??
```


## Random Forest 

```{r}
rf_fit <- train(voter_reg_status ~ ., 
                data = train_transformed_sample, # likely to improve with bigger training sample
                method = "rf",
                trControl = ctrl,
                verbose = FALSE)
rf_fit$bestTune
rf_model <- randomForest(voter_reg_status ~ .,
                         data = train_transformed_sample,
                         mtry = 10,
                         importance = TRUE)
rf_pred <- predict(rf_model, newdata = test_transformed, type = "class")
table_rf <- confusionMatrix(rf_pred, test_transformed$voter_reg_status)

# Accuracy rate 
Accuracy(y_pred = rf_pred, y_true = test_transformed$voter_reg_status) # 71.4%

# AUC computations (true positive rate vs. false positive rate)
# AUC for registration_complete 
AUC_function(rf_pred, test_transformed, "registration_complete") # 67.3%

# AUC for registration_started 
AUC_function(rf_pred, test_transformed, "registration_started") #70.1%

# AUC for any_interaction (integer overflow)
AUC_function(rf_pred, test_transformed, "any_interaction")

# AUC for no_interaction (integer overflow)
AUC_function(rf_pred, test_transformed, "no_interaction")
```


## Ordinal Logistic (TO DO)

```{r}
ord_logit_fit <- train(voter_reg_status ~ .,
                       data = train_transformed_sample,
                       method = "polr",
                       trControl = ctrl,
                       verbose = FALSE)

ord_logit_model <- MASS::polr(voter_reg_status ~ .,
                  data = train_transformed_sample) # error that says rank-deficient... perfect multicollinearity, but removed highly correlated variables already... might be factor variables (state)

ord_logit_pred <- predict(ord_logit_model, newdata = test_transformed, type = "class")
table_logit <- table(test_transformed$voter_reg_status, ord_logit_pred)

# Accuracy rate 
Accuracy(y_pred = ord_logit_pred, y_true = test_transformed$voter_reg_status)

# AUC computations (true positive rate vs. false positive rate)
# AUC for registration_complete 
AUC_function(ord_logit_pred, test_transformed, "registration_complete")

# AUC for registration_started 
AUC_function(ord_logit_pred, test_transformed, "registration_started")

# AUC for any_interaction 
AUC_function(ord_logit_pred, test_transformed, "any_interaction")

# AUC for no_interaction 
AUC_function(ord_logit_pred, test_transformed, "no_interaction")
```


## Neural Network 

```{r}
nnet_fit <- train(voter_reg_status ~ ., 
                data = train_transformed_sample,
                method = "nnet",
                trControl = ctrl,
                verbose = FALSE)
nnet_fit$bestTune

nnet_model <- nnet(voter_reg_status ~ .,
                  data = train_transformed_sample,
                  size = 5, # from nnet_fit$bestTune
                  decay = 0.1) # from nnet_fit$bestTune
nnet_pred <- predict(nnet_model, newdata = test_transformed, type = "class")
nnet_pred <- factor(nnet_pred,
                    levels = c("no_interaction", "any_interaction", 
                               "registration_started", "registration_complete"),
                    labels = c("no_interaction", "any_interaction", 
                               "registration_started", "registration_complete"))
table_nnet <- confusionMatrix(nnet_pred, test_transformed$voter_reg_status)

# Accuracy rate 
Accuracy(y_pred = nnet_pred, y_true = test_transformed$voter_reg_status) # 70.1%

# AUC computations (true positive rate vs. false positive rate)
# AUC for registration_complete 
AUC_function(nnet_pred, test_transformed, "registration_complete") # 60.1%

# AUC for registration_started
AUC_function(nnet_pred, test_transformed, "registration_started") # 80.4% 

# AUC for any_interaction (integer overflow)
AUC_function(nnet_pred, test_transformed, "any_interaction")

# AUC for no_interaction (integer overflow)
AUC_function(nnet_pred, test_transformed, "no_interaction")
```

## xgboost (linear)

```{r}
xgboost_fit <- train(voter_reg_status ~ .,
                     data = train_transformed_sample,
                     method = "xgbLinear",
                     trControl = ctrl,
                     verbose = FALSE)
```

## xgboost (tree)

```{r}
xgboost_tree_fit <- train(voter_reg_status ~ .,
                     data = train_transformed_sample,
                     method = "xgbTree",
                     trControl = ctrl,
                     verbose = FALSE)
```


## gbm 

```{r}
gbm_fit <- train(voter_reg_status ~ ., 
                 data = train_transformed_sample,
                 method = "gbm",
                 trControl = ctrl, 
                 verbose = FALSE)
gbm_fit$bestTune # includes the best parameters 
gbm_model <- gbm(voter_reg_status ~ .,
                 distribution = "multinomial",
                 data = train_transformed_sample,
                 n.trees = 150, # parameter determined by 10-fold cross validation
                 interaction.depth = 3, # parameter determined by 10-fold cross validation
                 shrinkage = 0.1, # parameter determined by 10-fold cross validation
                 n.minobsinnode = 10) # parameter determined by 10-fold cross validation
gbm_pred <- predict(gbm_model, 
                    newdata = test_transformed,
                    n.trees = 150,
                    type = "response")
gbm_pred <- gbm_transform_function(gbm_pred) # transform predictions into a dataset that can be compared to the test dataset
table_gbm <- confusionMatrix(gbm_pred, test_transformed$voter_reg_status)

# Accuracy rate 
Accuracy(y_pred = gbm_pred, y_true = test_transformed$voter_reg_status) # 71.4%

# AUC computations (true positive rate vs. false positive rate)
# AUC for registration_complete 
AUC_function(gbm_pred, test_transformed, "registration_complete") # 62.6%

# AUC for registration_started
AUC_function(gbm_pred, test_transformed, "registration_started") # 77.0%

# AUC for any_interaction (integer overflow...)
AUC_function(gbm_pred, test_transformed, "any_interaction")

# AUC for no_interaction (integer overflow...) 
AUC_function(gbm_pred, test_transformed, "no_interaction")

```

## Bayesian modeling 

```{r}
by_grp_bayesian <- master %>% group_by(voter_reg_status)
training_bayesian <- sample_n(by_grp_bayesian, 5000) #20K observations to start
training_bayesian$state <- NULL

bayes_fit <- stan_polr(voter_reg_status ~ .,
                       data = training_bayesian,
                       method = "logistic",
                       prior = R2(.2)) # memory exhausted.... Bayesian isn't gonna work 

```

















