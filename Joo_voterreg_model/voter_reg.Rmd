---
title: "voter_reg_modeling"
output: html_document
---

# 1. Sources & Libraries 

```{r, quietly=TRUE}
source('config/init.R')
source('config/pgConnect.R')
source('config/voter_regfunctions.R') # all functions are here
pg <- pgConnect()

packages.used <- c("lubridate", "ggplot2", "caret", 
                   "reshape2", "dplyr", 
                   "MLmetrics", "e1071", "tree", "rstanarm", "parallel", 
                   "doMC", "xgboost")

#check packages that need to be installed
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))

#install additional packages 
if (length(packages.needed) > 0) {
  install.packages(packages.needed, dependencies = TRUE)
}

library(lubridate)
library(reshape2)
library(caret)
library(ggplot2)
library(MLmetrics)
library(tree)
library(nnet)
library(parallel)
library(doMC)
library(mice)
library(xgboost)
library(dplyr)
```

# 2. Load datasets 

```{r}
# Users dataset 

users_query <- 
"SELECT u.northstar_id,
u.created_at,
u.last_logged_in,
u.last_accessed,
u.SOURCE,
u.birthdate,
u.first_name,
u.state,
u.zipcode,
u.cio_status,
u.sms_status,
u.voter_registration_status
FROM users u
WHERE u.subscribed_member = 'true'
	AND u.country = 'US'
	AND u.birthdate <= current_date - INTERVAL '18 years'" # removing underage members in users file 

users <- runQuery(users_query)

# phoenix_events dataset 

phoenix_query <- "SELECT 
	northstar_id,
	event_datetime,
	event_name,
	event_source,
	campaign_id,
	page_utm_medium,
	parent_source,
	browser_size
FROM phoenix_events
WHERE northstar_id IS NOT NULL 
	AND event_name IN ('view', 'visit', 'open modal', 'share action completed', 'clicked voter registration action', 'facebook share posted', 'photo-submission_action', 'clicked register-submit', 'Successful Reportback', 'text-submission-action', 'referral-submission-action')"

phoenix <- runQuery(phoenix_query)

# member_event_log dataset 

mel_query <- "SELECT 
	m.northstar_id,
	m.timestamp,
	m.action_type,
	m.SOURCE
FROM member_event_log m
WHERE m.northstar_id IS NOT NULL"

mel <- runQuery(mel_query)

# campaign_activity dataset 

ca_query <- "SELECT c.northstar_id,
c.campaign_run_id,
c.post_type,
c.reportback_volume,
c.post_status,
c.quantity,
c.signup_source,
c.post_source,
c.signup_created_at,
c.reported_back,
c.post_attribution_date
FROM campaign_activity c
WHERE c.northstar_id IS NOT NULL"

campaign <- runQuery(ca_query)

# email data

email_query <- "SELECT customer_id AS northstar_id,
email_address,
template_id, 
timestamp,
event_type
FROM email_event 
WHERE customer_id IS NOT NULL"

email <- runQuery(email_query)

# SMS

SMS_mes <- "SELECT 
northstar_id,
click_time AS SMS_time,
'SMS message' AS action_type
FROM bertly_clicks
WHERE northstar_id IS NOT NULL
UNION ALL 
	SELECT 
		id AS northstar_id,
		last_messaged_at AS SMS_time,
		'SMS link click' AS action_type
	FROM northstar.users 
	WHERE id IS NOT NULL 
		AND last_messaged_at IS NOT NULL"

sms <- runQuery(SMS_mes)

# Turbovote file 
turbo_query <- "SELECT 
	nsid AS northstar_id,
	SOURCE,
	campaign_id,
	ds_vr_status,
	ds_registration_date,
	file
FROM turbovote_file
WHERE nsid IS NOT null"

turbo <- runQuery(turbo_query)  
```

# Save as R data files 

```{r}
saveRDS(users, "Rdata/users.rds")
saveRDS(phoenix, "Rdata/phoenix.rds")
saveRDS(campaign, "Rdata/campaign.rds")
saveRDS(email, "Rdata/email.rds")
saveRDS(sms, "Rdata/sms.rds")
saveRDS(turbo, "Rdata/turbo.rds")
saveRDS(mel, "Rdata/mel.rds")
```

# Load R data files 

```{r}
users <- readRDS("Rdata/users.rds")
phoenix <- readRDS("Rdata/phoenix.rds")
campaign <- readRDS("Rdata/campaign.rds")
email <- readRDS("Rdata/email.rds")
sms <- readRDS("Rdata/sms.rds")
turbo <- readRDS("Rdata/turbo.rds")
mel <- readRDS("Rdata/mel.rds")
```


# Data wrangling 

## Remove records of under 18 northstar_ids in all datasets 

```{r}
# only keep rows whose age < 18, in US, and members in relevant datasets. 
phoenix <- remove18(phoenix, users)
campaign <- remove18(campaign, users)
email <- remove18(email, users)
sms <- remove18(sms, users)
turbo <- remove18(turbo, users)
mel <- remove18(mel, users)
```

## Extracting predicted feature (voter registration status)

```{r}
# a part of this code will soon become obsolete as Jen is leading the sprint to combine for all columns 
reg_status <- predicted_feature(users, turbo, campaign, phoenix, email)
```


## Extracting demographic features 

```{r}
# gender feature 
gender <- gender_feature(users)

# age feature 
age <- age_feature(users)

# SES feature 
ses <- ses_feature(users)

# state and whether it turned blue/red in 2016 election 
state_politics <- dem_rep_feature(users)
```

## Extracting behavioral features 

```{r}
# returns variables of email clicked, converted, opened, unsubscribed & total number of email actions per northstar_id  
email_count <- email_feature(email)

# returns columns of SMS action by type & total number of sms actions per northstar_id 
sms_count <- sms_feature(sms)

# returns columns of browser size by northstar_id 
browser_size <- browser_size_feature(phoenix)

# returns number of total actions per northstar_id 
total_action <- total_actions_feature(phoenix, campaign, email, sms)

# whether or not someone has reportedback ever (according to campaigns)
rb_status <- rb_feature(campaign, users)

# returns time of day activity level (day broken down by "morning", "afternoon", "evening", "night")
time_of_day <- timeday_feature(mel, users) 

# monthly active membership eligible action count by action type 
mam_actions <- MAM_action_feature(mel)

# whether or not last active within 1 month, 3 months, 6 months, 1 year 
last_action <- last_action_feature(mel)
```

# Create a dataset with desired features 

```{r}
master <- 
  reg_status %>% 
  left_join(gender, by = "northstar_id") %>% 
  left_join(age, by = "northstar_id") %>%
  left_join(ses, by = "northstar_id") %>% 
  left_join(state_politics, by = "northstar_id") %>%
  left_join(email_count, by = "northstar_id") %>% 
  left_join(sms_count, by = "northstar_id") %>%
  left_join(browser_size, by = "northstar_id") %>% 
  left_join(total_action, by = "northstar_id") %>%
  left_join(rb_status, by = "northstar_id") %>%
  left_join(time_of_day, by = "northstar_id") %>%
  left_join(mam_actions, by = "northstar_id") %>%
  left_join(last_action, by = "northstar_id")
  
master <- replace_na_numeric(master) # replace NAs in numeric columns with 0's
# master <- multi_imput(master) # use multiple imputation to fill in for missing values
master <- replace_na_else(master) # replace NAs in non-numeric columns with "unknown" 
```

## Identify & eliminate near zero-variance variables

(zero-variance variables are variables that have only a handful of unique values that occur with very low frequency - may need to be eliminated prior to modeling for fit to be stable)

```{r}
df_list <- remove_nzv(master) 

master <- df_list[[2]] # keeps only the dataframe
```

## Identify & eliminate highly correlated predictors

```{r}
df_list2 <- remove_highcor(master)

master <- df_list2[[3]] # keeps only the dataframe
```

## Finalize master dataset with desired ordered factor levels 
(Creates a no_interaction variable)

```{r}
master <- master_final(master)
```

## Remove datasets no longer needed to free up RAM 

```{r}
rm(age, browser_size, email_count, gender, rb_status, reg_status,
   ses, sms_count, state_politics, time_of_day, total_action, df_list, df_list2)

rm(campaign, combined, email, mel, no_interaction_sample, only_three, phoenix,
   sms, turbo, users)

rm(mam_actions, non_num, samp)

```


# Split into training & testing

### Divide into training and testing 

```{r}
in_train <- createDataPartition(y = master$voter_reg_status, p = 3 / 4, list = FALSE)
training <- master[in_train, ]
testing  <- master[-in_train, ]
```

The dataset is unbalanced because there is a significantly greater number of "interaction" than "registration complete" & "uncertain" values, which would bias the model into favoring predictions for those who have "interacted" with any voter registration CTA. I will use the caret upsample function to increase the other two values, with replacement. 

(The up sampling should be done to the training set ONLY. The testing set should maintain the unbalanced classes.)  

```{r}
up_train <- upSample(x = select(training, -c(voter_reg_status, northstar_id)),
                     y = training$voter_reg_status,
                     yname = "voter_reg_status") #upSample reduces the number of interaction values -- explore further (USE SMOTE??)
```

Centering and scaling data ensures that some features do not dominate the algorithm AND and the features are unit-independent. 

```{r}
preprocvalues <- preProcess(up_train, method = c("center", "scale")) # estimates required parameters to be centered & scaled 
train_transformed <- predict(preprocvalues, up_train) # this function actually centers and scales based on the parameters defined above 
test_transformed <- predict(preprocvalues, testing)
```

randomly sample b/c of memory issues....

```{r}
by_grp <- train_transformed %>% group_by(voter_reg_status)
train_transformed_sample <- sample_n(by_grp, 10000)

rm(master, by_grp, in_train, testing, train_transformed, training, up_train)
```


Using the caret package to set a 10-fold cross-validation for models with tuning parameters. 

```{r}
ctrl <- trainControl(method = "cv",
                     number = 10,
                     summaryFunction = multiClassSummary, # computes accuracy & Kappa statistics, sensitivity values - might substitute prSummary (precision & recall)...  explore
                     classProbs = TRUE)
```

## Tree 

```{r}
numCors <- detectCores() - 1
registerDoMC(cores = numCors)

set.seed(12345)

tree_model <- tree(voter_reg_status ~ .,
                   data = select(train_transformed_sample, -state)) # removing state variable b/c too many factor levels
tree_predictions <- predict(tree_model, newdata = test_transformed, type = "class")
table_tree <- table(test_transformed$voter_reg_status, tree_predictions)

# simple accuracy rate
Accuracy(y_pred = tree_predictions, y_true = test_transformed$voter_reg_status) 

# AUC computations (true positive rate vs. false positive rate)
# AUC for registration_complete 
AUC_function(tree_predictions, test_transformed, "registration_complete")

# AUC for uncertain 
AUC_function(tree_predictions, test_transformed, "registration_started")

# AUC for interaction 
AUC_function(tree_predictions, test_transformed, "any_interaction") # error - integer overflow ??
```


## Random Forest 

```{r}
rf_fit <- train(voter_reg_status ~ ., 
                data = train_transformed,
                method = "rf",
                trControl = ctrl,
                verbose = FALSE)

rf_model <- randomForest(voter_reg_status ~ .,
                         data = train_transformed,
                         ntree = 500,
                         mtry = 4,
                         importance = TRUE)
```


## Ordinal Logistic

```{r}
ord_logit_fit <- train(voter_reg_status ~ .,
                       data = train_transformed,
                       method = "polr",
                       trControl = ctrl,
                       verbose = FALSE)

ord_logit_model <- MASS::polr(voter_reg_status ~ .,
                  data = train_transformed_sample)
ord_logit_pred <- predict(ord_logit_model, newdata = test_transformed, type = "class")
table_logit <- table(test_transformed$voter_reg_status, ord_logit_pred)

# Accuracy rate 
Accuracy(y_pred = ord_logit_pred, y_true = test_transformed$voter_reg_status)

# AUC computations (true positive rate vs. false positive rate)
# AUC for registration_complete 
AUC_function(ord_logit_pred, test_transformed, "registration_complete")

# AUC for uncertain 
AUC_function(ord_logit_pred, test_transformed, "registration_started")

# AUC for interaction 
AUC_function(ord_logit_pred, test_transformed, "any_interaction")
```


## Neural Network 

```{r}
nnet_fit <- train(voter_reg_status ~ ., 
                data = train_transformed_sample,
                method = "nnet",
                trControl = ctrl,
                verbose = FALSE)

nnet_model <- nnet(voter_reg_status ~ .,
                  data = train_transformed_sample,
                  size = 2)
nnet_pred <- predict(nnet_model, newdata = test_transformed, type = "class")
table_nnet <- table(test_transformed$voter_reg_status, nnet_pred)

# Accuracy rate 
Accuracy(y_pred = nnet_pred, y_true = test_transformed$voter_reg_status)

# AUC computations (true positive rate vs. false positive rate)
# AUC for registration_complete 
AUC_function(nnet_pred, test_transformed, "registration_complete")

# AUC for uncertain (lowest AUC - explore how to improve prediction for uncertain)
AUC_function(nnet_pred, test_transformed, "uncertain")

# AUC for interaction 
AUC_function(nnet_pred, test_transformed, "interaction")
```

## Bayesian modeling 

```{r}
stan_transformed <- predict(preprocvalues, training)

bayes_fit <- stan_polr(voter_reg_status ~ .,
                       data = train_transformed_sample,
                       method = "logistic",
                       prior = R2(.2))

```

## xgboost

```{r}

```

## gbm 

```{r}

```
















